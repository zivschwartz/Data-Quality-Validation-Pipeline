{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from data_quality import *\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "\n",
    "\n",
    "import warnings\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_flights, dirty_flights = partition_data_files('tmp/FLIGHTS/*.csv')\n",
    "clean_fb, dirty_fb = partition_data_files('tmp/FBPosts/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@description: this is the same function from assignment2; infers schema from a given csv file\n",
    "@params: csv_file - string csv filepath to read\n",
    "         column_names - string list, names of the columns along the csv header\n",
    "@return: schema - inferred schema\n",
    "'''\n",
    "def infer_schema_from_csv(csv_file, column_names):\n",
    "    data_stats = tfdv.generate_statistics_from_csv(data_location=csv_file, column_names=column_names)\n",
    "    \n",
    "    #tfdv.visualize_statistics(data_stats)\n",
    "    schema = tfdv.infer_schema(statistics=data_stats)\n",
    "    \n",
    "    return schema \n",
    "\n",
    "'''\n",
    "@description: same function from assignment 2; determines whether the new csv file \n",
    "              has anomalies against the schema\n",
    "@params: csv_file - new csv filepath to compare against schema\n",
    "         schema - schema against which to compare the new csv file\n",
    "@return: True - if there are anomalies\n",
    "          False - if there are no anomalies\n",
    "'''\n",
    "def has_anomalies(csv_file, schema):\n",
    "    #get column names from passed in schema\n",
    "    cols = [f.name for f in schema.feature]\n",
    "    data_stats = tfdv.generate_statistics_from_csv(data_location=csv_file, column_names=cols)\n",
    "\n",
    "    # Check eval data for errors by validating the eval data stats using the previously inferred schema\n",
    "    anomalies = tfdv.validate_statistics(statistics=data_stats, schema=schema)\n",
    "    \n",
    "    #tfdv.display_anomalies(anomalies)\n",
    "\n",
    "    if len(anomalies.anomaly_info) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "'''\n",
    "@description: takes the current csv file and updates the passed in schema to include its values as \"valid\"\n",
    "@params: csv_file - new csv file to add to the schema\n",
    "         schema - schema to be updated\n",
    "@return: updated_schema - new schema with anomalies of csv_file param added\n",
    "'''\n",
    "def update_schema(csv_file, schema):\n",
    "    #get column names from passed in schema\n",
    "    cols = [f.name for f in schema.feature]\n",
    "    new_batch_stats = tfdv.generate_statistics_from_csv(data_location=csv_file, column_names=cols)\n",
    "\n",
    "    # Check eval data for errors by validating the eval data stats using the previously inferred schema\n",
    "    updated_schema = tfdv.update_schema(schema, new_batch_stats)\n",
    "    #tfdv.display_schema(schema=updated_schema)\n",
    "\n",
    "    return updated_schema\n",
    "\n",
    "'''\n",
    "@description: updates the schema for num_files number of files\n",
    "@params: all_filenames - string list of all csv filenames\n",
    "         num_files - the number of files we want to include in our \"acceptable\" schema\n",
    "@return: updated_schema - new schema with anomalies of all num_files number of csv files added\n",
    "'''\n",
    "def acceptable_schema(all_filenames, num_files):\n",
    "    files_to_update = all_filenames[0:num_files]\n",
    "    successful = True\n",
    "    \n",
    "    for i, file in enumerate(files_to_update):\n",
    "        print(\"Reading file: \", file)\n",
    "        \n",
    "        #for the first file read in, infer its schema\n",
    "        if i == 0:\n",
    "            columns = list(pd.read_csv(file, error_bad_lines=False).columns)\n",
    "            schema = infer_schema_from_csv(file, columns)\n",
    "        else:\n",
    "            schema = update_schema(file, schema) #updated schema\n",
    "            #sanity check to make sure this is working\n",
    "            if has_anomalies(file, schema):\n",
    "                print('Unsuccessful schema update on file number {}: {}'.format(i,file))\n",
    "                successful = False\n",
    "                break\n",
    "                \n",
    "    if successful:\n",
    "        print(\"Schema successfully updated for all {} files\".format(num_files))\n",
    "        \n",
    "    return updated_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file:  tmp/FLIGHTS/FLIGHTS_clean_734472.csv\n",
      "Reading file:  tmp/FLIGHTS/FLIGHTS_clean_734473.csv\n",
      "Reading file:  tmp/FLIGHTS/FLIGHTS_clean_734474.csv\n",
      "Reading file:  tmp/FLIGHTS/FLIGHTS_clean_734475.csv\n",
      "Reading file:  tmp/FLIGHTS/FLIGHTS_clean_734476.csv\n",
      "Schema successfully updated for all 5 files\n"
     ]
    }
   ],
   "source": [
    "updated_schema = acceptable_schema(clean_flights,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
